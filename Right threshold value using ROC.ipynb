{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3baaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07513a99",
   "metadata": {},
   "source": [
    "making a new random classification dataset of our own where samples are rows classes are output labels weights are assignend to keep the data balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82ea543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples = 2000 , n_classes = 2, weights = [1,1], random_state=1)  #weights are assigned so that it becomes a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29a8e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # 2000 rows and 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05a7d73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6d90159",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b02b7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b6594",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4a12f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc score 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "ytrain_pred = rf.predict_proba(X_train)\n",
    "print('RF train roc score {}'.format(roc_auc_score(y_train,ytrain_pred[:,1]))) #we are only taking the last column i.e 0 then we will apply threshold on that column to check whether the values are less or greater than 0.5 that is why we wont be needing our first column because the work can be done on either of two\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6ec0b",
   "metadata": {},
   "source": [
    "predict_proba() is used to predict the probabiltites of the classes i.e what is the probabilty that it belongs to class 1 or class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24b7b899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.01, 0.99],\n",
       "       ...,\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.25, 0.75]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_pred #we have columns for class 1 and 0 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d5df9",
   "metadata": {},
   "source": [
    "if value is greater than 0 consider it as 1 and if less than 0 consider it as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4f860cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF test roc score 0.981311111111111\n"
     ]
    }
   ],
   "source": [
    "ytest_pred = rf.predict_proba(X_test)\n",
    "print('RF test roc score {}'.format(roc_auc_score(y_test,ytest_pred[:,1]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab82cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.99],\n",
       "       [0.98, 0.02],\n",
       "       [0.02, 0.98],\n",
       "       ...,\n",
       "       [0.03, 0.97],\n",
       "       [0.99, 0.01],\n",
       "       [0.  , 1.  ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2eea9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f085e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc score 0.9863568922694498\n",
      "RF test roc score 0.9885777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#for train data\n",
    "\n",
    "ytrain_pred = lr.predict_proba(X_train)\n",
    "print('RF train roc score {}'.format(roc_auc_score(y_train,ytrain_pred[:,1]))) #we are only taking the last column i.e 0 then we will apply threshold on that column to check whether the values are less or greater than 0.5 that is why we wont be needing our first column because the work can be done on either of two\n",
    "\n",
    "#for test data\n",
    "\n",
    "ytest_pred = lr.predict_proba(X_test)\n",
    "print('RF test roc score {}'.format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041cf28",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c7f062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc score 0.981670071491109\n",
      "RF test roc score 0.9426111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#for train data\n",
    "\n",
    "ytrain_pred = knn.predict_proba(X_train)\n",
    "print('RF train roc score {}'.format(roc_auc_score(y_train,ytrain_pred[:,1]))) #we are only taking the last column i.e 0 then we will apply threshold on that column to check whether the values are less or greater than 0.5 that is why we wont be needing our first column because the work can be done on either of two\n",
    "\n",
    "#for test data\n",
    "\n",
    "ytest_pred = knn.predict_proba(X_test)\n",
    "print('RF test roc score {}'.format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12b64b",
   "metadata": {},
   "source": [
    "# ADABoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c5f1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc score 0.9975081174960356\n",
      "RF test roc score 0.9826111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "#for train data\n",
    "\n",
    "ytrain_pred = ada.predict_proba(X_train)\n",
    "print('RF train roc score {}'.format(roc_auc_score(y_train,ytrain_pred[:,1]))) #we are only taking the last column i.e 0 then we will apply threshold on that column to check whether the values are less or greater than 0.5 that is why we wont be needing our first column because the work can be done on either of two\n",
    "\n",
    "#for test data\n",
    "\n",
    "ytest_pred = ada.predict_proba(X_test)\n",
    "print('RF test roc score {}'.format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfd11e",
   "metadata": {},
   "source": [
    "### Focus on selecting the best threshold value for max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed2fca3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      0.99\n",
       " 1      0.02\n",
       " 2      0.98\n",
       " 3      0.90\n",
       " 4      0.52\n",
       "        ... \n",
       " 595    0.02\n",
       " 596    0.01\n",
       " 597    0.97\n",
       " 598    0.01\n",
       " 599    1.00\n",
       " Length: 600, dtype: float64,\n",
       " 0      0.991861\n",
       " 1      0.000008\n",
       " 2      0.966929\n",
       " 3      0.761539\n",
       " 4      0.779443\n",
       "          ...   \n",
       " 595    0.024239\n",
       " 596    0.000003\n",
       " 597    0.984385\n",
       " 598    0.001147\n",
       " 599    0.989540\n",
       " Length: 600, dtype: float64,\n",
       " 0      0.559186\n",
       " 1      0.463282\n",
       " 2      0.538202\n",
       " 3      0.509875\n",
       " 4      0.490344\n",
       "          ...   \n",
       " 595    0.461121\n",
       " 596    0.441377\n",
       " 597    0.532403\n",
       " 598    0.441720\n",
       " 599    0.559890\n",
       " Length: 600, dtype: float64,\n",
       " 0      1.0\n",
       " 1      0.0\n",
       " 2      0.8\n",
       " 3      0.8\n",
       " 4      0.4\n",
       "       ... \n",
       " 595    0.0\n",
       " 596    0.0\n",
       " 597    1.0\n",
       " 598    0.2\n",
       " 599    0.8\n",
       " Length: 600, dtype: float64]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "#appending all the probabilites of all the models in  a list by taking the second column probability\n",
    "\n",
    "for model in [rf,lr,ada,knn]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))  \n",
    "\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b15e2e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.559186</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.463282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.538202</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.509875</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.779443</td>\n",
       "      <td>0.490344</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.461121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.441377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>0.532403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.441720</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    3\n",
       "0    0.99  0.991861  0.559186  1.0\n",
       "1    0.02  0.000008  0.463282  0.0\n",
       "2    0.98  0.966929  0.538202  0.8\n",
       "3    0.90  0.761539  0.509875  0.8\n",
       "4    0.52  0.779443  0.490344  0.4\n",
       "..    ...       ...       ...  ...\n",
       "595  0.02  0.024239  0.461121  0.0\n",
       "596  0.01  0.000003  0.441377  0.0\n",
       "597  0.97  0.984385  0.532403  1.0\n",
       "598  0.01  0.001147  0.441720  0.2\n",
       "599  1.00  0.989540  0.559890  0.8\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenating all the series into the dataframe where the columns of df represent the models' name for eg rf=0, lr=1, ada=2, knn=3 \n",
    "\n",
    "df_final = pd.concat(pred, axis=1) \n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0be594d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.885262\n",
       "1      0.120823\n",
       "2      0.821283\n",
       "3      0.742853\n",
       "4      0.547447\n",
       "         ...   \n",
       "595    0.126340\n",
       "596    0.112845\n",
       "597    0.871697\n",
       "598    0.163217\n",
       "599    0.837357\n",
       "Length: 600, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_mean = df_final.mean(axis=1) #taking mean on the axis\n",
    "df_final_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42d6e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC Score 0.9846333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Test ROC Score {}'.format(roc_auc_score(y_test,df_final_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5402ad1",
   "metadata": {},
   "source": [
    "## Calculate the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f57ba955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9134413 , 0.9134413 , 0.90656694, 0.90577475, 0.81198866,\n",
       "       0.81162833, 0.79380736, 0.7930558 , 0.78140513, 0.78071156,\n",
       "       0.76586354, 0.76537124, 0.72402563, 0.71887362, 0.70847576,\n",
       "       0.70393711, 0.65942282, 0.65743537, 0.61494697, 0.60864346,\n",
       "       0.5896569 , 0.58925354, 0.58156376, 0.57550386, 0.55308969,\n",
       "       0.54969563, 0.54744674, 0.54486186, 0.54095371, 0.52127948,\n",
       "       0.50615858, 0.49866892, 0.45200602, 0.38318654, 0.37879719,\n",
       "       0.35183098, 0.34586612, 0.24154122, 0.23640421, 0.2296341 ,\n",
       "       0.22896893, 0.20438001, 0.20348417, 0.12052718, 0.1203351 ,\n",
       "       0.10632697])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, df_final_mean)\n",
    "# Print the threshold values\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56286d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(df_final_mean > thres,1,0) # for all predictions made if its greater than 0.5 then covert to 1 else just convert into 0\n",
    "    accuracy.append(accuracy_score(y_test, y_pred, normalize = True)) #append the accuracy in the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb331b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now making the list into the dataframe\n",
    "\n",
    "accuracy = pd.concat([pd.Series(thresholds), pd.Series(accuracy)], axis = 1)\n",
    "\n",
    "accuracy.columns = ['thresholds','accuracy']\n",
    "accuracy.sort_values(by = 'accuracy', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e64184f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.452006</td>\n",
       "      <td>0.961667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.498669</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.549696</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.506159</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.521279</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.544862</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.547447</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.553090</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.540954</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.575504</td>\n",
       "      <td>0.951667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.581564</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.383187</td>\n",
       "      <td>0.948333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.589254</td>\n",
       "      <td>0.948333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.589657</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.378797</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.608643</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.614947</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.351831</td>\n",
       "      <td>0.938333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.657435</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.345866</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.659423</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.703937</td>\n",
       "      <td>0.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.708476</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.718874</td>\n",
       "      <td>0.911667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.241541</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.236404</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.229634</td>\n",
       "      <td>0.871667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.228969</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.765371</td>\n",
       "      <td>0.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.204380</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.203484</td>\n",
       "      <td>0.843333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.780712</td>\n",
       "      <td>0.831667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.781405</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.793056</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.793807</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.811628</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811989</td>\n",
       "      <td>0.788333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.120527</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.120335</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905775</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906567</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.106327</td>\n",
       "      <td>0.501667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913441</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.913441</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "32    0.452006  0.961667\n",
       "31    0.498669  0.958333\n",
       "25    0.549696  0.958333\n",
       "30    0.506159  0.956667\n",
       "29    0.521279  0.956667\n",
       "27    0.544862  0.956667\n",
       "26    0.547447  0.956667\n",
       "24    0.553090  0.956667\n",
       "28    0.540954  0.955000\n",
       "23    0.575504  0.951667\n",
       "22    0.581564  0.950000\n",
       "33    0.383187  0.948333\n",
       "21    0.589254  0.948333\n",
       "20    0.589657  0.946667\n",
       "34    0.378797  0.946667\n",
       "19    0.608643  0.945000\n",
       "18    0.614947  0.943333\n",
       "35    0.351831  0.938333\n",
       "17    0.657435  0.936667\n",
       "36    0.345866  0.936667\n",
       "16    0.659423  0.935000\n",
       "15    0.703937  0.918333\n",
       "14    0.708476  0.916667\n",
       "13    0.718874  0.911667\n",
       "12    0.724026  0.910000\n",
       "37    0.241541  0.878333\n",
       "38    0.236404  0.876667\n",
       "39    0.229634  0.871667\n",
       "40    0.228969  0.870000\n",
       "11    0.765371  0.856667\n",
       "10    0.765864  0.855000\n",
       "41    0.204380  0.845000\n",
       "42    0.203484  0.843333\n",
       "9     0.780712  0.831667\n",
       "8     0.781405  0.830000\n",
       "7     0.793056  0.815000\n",
       "6     0.793807  0.813333\n",
       "5     0.811628  0.790000\n",
       "4     0.811989  0.788333\n",
       "43    0.120527  0.626667\n",
       "44    0.120335  0.625000\n",
       "3     0.905775  0.508333\n",
       "2     0.906567  0.506667\n",
       "45    0.106327  0.501667\n",
       "1     0.913441  0.500000\n",
       "0     1.913441  0.500000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy #the threshold with highest accuracy is selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a22d7",
   "metadata": {},
   "source": [
    "## plotting the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b32bcdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, label = 'ROC')\n",
    "    plt.plot([0,1], [0,1], linestyle = '--')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    " \n",
    "plot_roc(fpr,tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
